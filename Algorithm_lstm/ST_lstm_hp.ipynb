{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "joT_io3y8Kck",
    "outputId": "03b9aa68-3d01-4e94-b593-760fe95bc58e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keras-tuner\n",
      "  Downloading keras_tuner-1.4.7-py3-none-any.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (2.15.0)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (24.1)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (2.31.0)\n",
      "Collecting kt-legacy (from keras-tuner)\n",
      "  Downloading kt_legacy-1.0.5-py3-none-any.whl.metadata (221 bytes)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (2024.7.4)\n",
      "Downloading keras_tuner-1.4.7-py3-none-any.whl (129 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.1/129.1 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading kt_legacy-1.0.5-py3-none-any.whl (9.6 kB)\n",
      "Installing collected packages: kt-legacy, keras-tuner\n",
      "Successfully installed keras-tuner-1.4.7 kt-legacy-1.0.5\n"
     ]
    }
   ],
   "source": [
    "\n",
    "!pip install keras-tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EYjKwFbT8oaM"
   },
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import keras_tuner as kt\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A32IZUgo8aPS"
   },
   "outputs": [],
   "source": [
    "# Load and preprocess the data\n",
    "train_data = pd.read_csv('/content/sarcasm_tam_train.csv')\n",
    "dev_data = pd.read_csv('/content/sarcasm_tam_dev.csv')\n",
    "test_data = pd.read_csv('/content/sarcasm_tam_test_without_labels.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jwOBMMW188Is",
    "outputId": "b6489f77-14d3-46cf-e83b-7f0bd030de49"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 30 Complete [00h 03m 01s]\n",
      "val_accuracy: 0.7929292917251587\n",
      "\n",
      "Best val_accuracy So Far: 0.8014520406723022\n",
      "Total elapsed time: 00h 44m 41s\n"
     ]
    }
   ],
   "source": [
    "# Clean and tokenize text data\n",
    "def clean_text(text):\n",
    "    text = re.sub(r'http\\S+', '', text)  # Remove URLs\n",
    "    text = re.sub(r'[^A-Za-z\\s]+', ' ', text)  # Remove special characters and digits\n",
    "    text = text.lower()  # Convert to lower case\n",
    "    return text\n",
    "\n",
    "train_data['cleaned_text'] = train_data['Text'].apply(clean_text)\n",
    "dev_data['cleaned_text'] = dev_data['Text'].apply(clean_text)\n",
    "test_data['cleaned_text'] = test_data['Text'].apply(clean_text)\n",
    "\n",
    "# Encode labels\n",
    "label_mapping = {'Non-sarcastic': 0, 'Sarcastic': 1}\n",
    "train_data['labels'] = train_data['labels'].map(label_mapping)\n",
    "dev_data['labels'] = dev_data['labels'].map(label_mapping)\n",
    "\n",
    "# Tokenize and pad sequences\n",
    "tokenizer = Tokenizer(num_words=10000)\n",
    "tokenizer.fit_on_texts(train_data['cleaned_text'])\n",
    "\n",
    "X_train = tokenizer.texts_to_sequences(train_data['cleaned_text'])\n",
    "X_dev = tokenizer.texts_to_sequences(dev_data['cleaned_text'])\n",
    "X_test = tokenizer.texts_to_sequences(test_data['cleaned_text'])\n",
    "\n",
    "max_sequence_length = 100\n",
    "X_train_padded = pad_sequences(X_train, maxlen=max_sequence_length)\n",
    "X_dev_padded = pad_sequences(X_dev, maxlen=max_sequence_length)\n",
    "X_test_padded = pad_sequences(X_test, maxlen=max_sequence_length)\n",
    "\n",
    "y_train = to_categorical(train_data['labels'])\n",
    "y_dev = to_categorical(dev_data['labels'])\n",
    "\n",
    "# Define the hypermodel function for Keras Tuner\n",
    "def build_model(hp):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(input_dim=10000, output_dim=hp.Int('embedding_dim', min_value=32, max_value=256, step=32), input_length=max_sequence_length))\n",
    "\n",
    "    for i in range(hp.Int('num_layers', 1, 3)):\n",
    "        model.add(LSTM(units=hp.Int(f'lstm_units_{i}', min_value=32, max_value=256, step=32),\n",
    "                       return_sequences=True if i < hp.Int('num_layers', 1, 3) - 1 else False))\n",
    "        model.add(Dropout(rate=hp.Float(f'dropout_{i}', min_value=0.1, max_value=0.5, step=0.1)))\n",
    "\n",
    "    model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "    model.compile(optimizer=hp.Choice('optimizer', ['adam', 'rmsprop']),\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Initialize and run the Hyperparameter Tuner\n",
    "tuner = kt.Hyperband(build_model,\n",
    "                     objective='val_accuracy',\n",
    "                     max_epochs=10,\n",
    "                     factor=3,\n",
    "                     directory='my_dir',\n",
    "                     project_name='intro_to_kt')\n",
    "\n",
    "tuner.search(X_train_padded, y_train, epochs=10, validation_data=(X_dev_padded, y_dev))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NDUVjuvY9CF3",
    "outputId": "125a4a2d-4412-4e3d-aa74-73a5eda564a1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters:\n",
      "{'embedding_dim': 224, 'num_layers': 1, 'lstm_units_0': 64, 'dropout_0': 0.1, 'optimizer': 'adam', 'lstm_units_1': 192, 'dropout_1': 0.2, 'lstm_units_2': 192, 'dropout_2': 0.4, 'tuner/epochs': 2, 'tuner/initial_epoch': 0, 'tuner/bracket': 2, 'tuner/round': 0}\n",
      "198/198 [==============================] - 1s 3ms/step\n",
      "Validation Accuracy: 0.8014520202020202\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.92      0.87      4630\n",
      "           1       0.70      0.47      0.56      1706\n",
      "\n",
      "    accuracy                           0.80      6336\n",
      "   macro avg       0.76      0.70      0.72      6336\n",
      "weighted avg       0.79      0.80      0.79      6336\n",
      "\n",
      "Development Set Macro F1 Score: 0.7152583352088222\n",
      "199/199 [==============================] - 1s 3ms/step\n",
      "Test predictions saved to 'sarcasm_tam_test_predictions_lstm.csv'\n"
     ]
    }
   ],
   "source": [
    "# Get the best model and hyperparameters\n",
    "best_model = tuner.get_best_models(num_models=1)[0]\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "print(\"Best hyperparameters:\")\n",
    "print(best_hps.values)\n",
    "\n",
    "# Evaluate the best model on the development set\n",
    "y_dev_pred = best_model.predict(X_dev_padded)\n",
    "y_dev_pred_classes = np.argmax(y_dev_pred, axis=1)\n",
    "y_dev_true = np.argmax(y_dev, axis=1)\n",
    "\n",
    "print(\"Validation Accuracy:\", accuracy_score(y_dev_true, y_dev_pred_classes))\n",
    "print(\"Classification Report:\\n\", classification_report(y_dev_true, y_dev_pred_classes))\n",
    "\n",
    "# Compute Macro F1 Score for development set\n",
    "macro_f1_dev = f1_score(y_dev_true, y_dev_pred_classes, average='macro')\n",
    "print(\"Development Set Macro F1 Score:\", macro_f1_dev)\n",
    "\n",
    "# Predict on the test set\n",
    "test_predictions = best_model.predict(X_test_padded)\n",
    "test_predictions_classes = np.argmax(test_predictions, axis=1)\n",
    "\n",
    "# Save the predictions to a CSV file\n",
    "test_results = test_data[['ID']].copy()\n",
    "test_results['Predicted_Label'] = test_predictions_classes\n",
    "test_results['Predicted_Label'] = test_results['Predicted_Label'].map({0: 'Non-sarcastic', 1: 'Sarcastic'})\n",
    "\n",
    "test_results.to_csv('/content/sarcasm_tam_test_predictions_lstm_hp_id.csv', index=False)\n",
    "print(\"Test predictions saved to 'sarcasm_tam_test_predictions_lstm.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wXA6tUenIYWJ"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
